{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "Hacker News is a site similar to reddit, where users submit aritcles and stories, which are then voted and commented on. Hacker News is very popular in the tech and startup world. In this project, we will explore a data set of posts on the Hacker News site. The data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). The full data set will not be used in this analysis, the submissions without any comments have been removed, and a random sample was taken of the remaining submissions. \n",
    "\n",
    "We will be looking specifcally at posts with the titles **Ask HN** and **Show HN**. These posts are submitted to either ask the community a specific question or show the community something, respectively. \n",
    "\n",
    "We will be looking at two specific questions in regards to these posts:\n",
    "* Do **Ask HN** or **Show HN** receive more comments on average?\n",
    "* Do posts created at certain times receive more comments on average?\n",
    "\n",
    "We will start by importing the libraries we need and reading the data into a list of lists. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader #import the reader definition from the csv module\n",
    "open_file = open('hacker_news.csv') \n",
    "read_file = reader(open_file) #use reader to parse the open_file\n",
    "hn = list(read_file) #convert the read_file into a list of lists\n",
    "\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of data, we can see the first row contains the headers. We will need to remove them from our working set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0] #extract the first row and assign to variable headers\n",
    "hn = hn[1:] #remove the headers row from the data set\n",
    "print(headers)\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sorting the Data by Post Type\n",
    "Now that we have a usable list to work with, we can begin sorting the data. First we will separate posts beginning with **Ask HN** and **Show HN**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = [] #Create three empty lists to sort the data\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn: \n",
    "    title = row[1] \n",
    "    if title.lower().startswith('ask hn'): #check what the title starts with and append to the appropriate list\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Average Number of Comments\n",
    "We have the posts separated by title, now we will see if which posts receive the highest average number of comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the code above that **Ask HN** posts receive more comments on average. We'll dive deeper into those posts next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour\n",
    "\n",
    "Now we will try to determine if there is a specific time of day that generates more comments on a post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the datetime module and calculate the number of ask posts created by hour\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6], int(post[4])])\n",
    "    \n",
    "#Create two frequency tables to look at posts per hour and comments per hour\n",
    "counts_by_hour ={}\n",
    "comments_by_hour = {}\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime('%H')\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = comment\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += comment\n",
    "\n",
    "comments_by_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Average Number Comments by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['03', 7.796296296296297],\n",
       " ['19', 10.8],\n",
       " ['13', 14.741176470588234],\n",
       " ['00', 8.127272727272727],\n",
       " ['02', 23.810344827586206],\n",
       " ['08', 10.25],\n",
       " ['06', 9.022727272727273],\n",
       " ['05', 10.08695652173913],\n",
       " ['18', 13.20183486238532],\n",
       " ['17', 11.46],\n",
       " ['11', 11.051724137931034],\n",
       " ['01', 11.383333333333333],\n",
       " ['04', 7.170212765957447],\n",
       " ['22', 6.746478873239437],\n",
       " ['14', 13.233644859813085],\n",
       " ['12', 9.41095890410959],\n",
       " ['15', 38.5948275862069],\n",
       " ['07', 7.852941176470588],\n",
       " ['10', 13.440677966101696],\n",
       " ['21', 16.009174311926607],\n",
       " ['23', 7.985294117647059],\n",
       " ['20', 21.525],\n",
       " ['09', 5.5777777777777775],\n",
       " ['16', 16.796296296296298]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a list of lists with the average number of comments per post by hour of the day\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.796296296296297, '03'],\n",
       " [10.8, '19'],\n",
       " [14.741176470588234, '13'],\n",
       " [8.127272727272727, '00'],\n",
       " [23.810344827586206, '02'],\n",
       " [10.25, '08'],\n",
       " [9.022727272727273, '06'],\n",
       " [10.08695652173913, '05'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.051724137931034, '11'],\n",
       " [11.383333333333333, '01'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [13.233644859813085, '14'],\n",
       " [9.41095890410959, '12'],\n",
       " [38.5948275862069, '15'],\n",
       " [7.852941176470588, '07'],\n",
       " [13.440677966101696, '10'],\n",
       " [16.009174311926607, '21'],\n",
       " [7.985294117647059, '23'],\n",
       " [21.525, '20'],\n",
       " [5.5777777777777775, '09'],\n",
       " [16.796296296296298, '16']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort and print the top 5 results in an easy to read list\n",
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the results\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"), avg))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per hour is 15:00. If we were to make an **Ask HN** post, this would be the ideal time to create it to get the most engagement. Referring back to the [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home) we see that the time zone is Eastern. So the hour of the most comments is 3 PM EST. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this project, we analyzed **Ask HN** and **Show HN** posts from the website Hacker News, in order to see whether either type of posts was better at generating comments, and if the time of day the post was created factored in to the amount of comments the post received. \n",
    "\n",
    "We found that the **Ask HN** posts had on average more comments per post than the **Show HN** posts. This is most likely due to the nature of the post, as it is inviting a discussion with other members of the site. When looking at the average number of comments per **Ask HN** posts by the hour in which they were posted, we determined that the hour of 3:00 PM EST is the ideal time to post and maximize the number of comments on t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
